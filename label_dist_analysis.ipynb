{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a48ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a996ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of new/augmented non-hateful memes in Extended Dataset:  2479\n"
     ]
    }
   ],
   "source": [
    "df_ex = pd.read_json(\"Data/Extended/ex_train.jsonl\", lines=True)\n",
    "\n",
    "print(\"Total number of new/augmented non-hateful memes in Extended Dataset: \", len(df_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60afec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Original) Train/Val/Test Set Label Counts:\n",
      "Train:\n",
      "label\n",
      "1    4779\n",
      "0    4779\n",
      "Name: count, dtype: int64\n",
      "Validation:\n",
      "label\n",
      "1    1195\n",
      "0    1195\n",
      "Name: count, dtype: int64\n",
      "Test:\n",
      "label\n",
      "0    1760\n",
      "1    1240\n",
      "Name: count, dtype: int64\n",
      "\n",
      "##################################################\n",
      "\n",
      "(Extended) Train/Val/Test Set Label Counts:\n",
      "Train:\n",
      "label\n",
      "0    5530\n",
      "1    5530\n",
      "Name: count, dtype: int64\n",
      "Validation:\n",
      "label\n",
      "0    1383\n",
      "1    1383\n",
      "Name: count, dtype: int64\n",
      "Test:\n",
      "label\n",
      "0    1760\n",
      "1    1240\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Label distribution (original vs aug) in Extended Dataset:\n",
      "Train:\n",
      "label\n",
      "0    1655\n",
      "Name: count, dtype: int64\n",
      "Validation:\n",
      "label\n",
      "0    381\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Printing label distribution in the original and extended datasets\n",
    "# The function prints the label counts for training, validation\n",
    "###############################################################################\n",
    "# Note that we are not using val_seen.jsonl and val_unseen.jsonl to avoid distribution shift in case of extended dataset\n",
    "# so to keep the validation set consistent, we are splitting the training set into train and validation\n",
    "###############################################################################\n",
    "# It also shows the label distribution in the extended dataset, if applicable\n",
    "# The function takes a boolean parameter `isExt` to determine if the extended dataset is used\n",
    "# It also uses a random seed for reproducibility in sampling (same as used in the original train/val split)\n",
    "def print_stats(isExt, RANDOM_SEED=42):\n",
    "    # Load your data\n",
    "    train_df = pd.read_json(\"Data/Original/train.jsonl\", lines=True)\n",
    "    if(isExt):\n",
    "        df_train_ex = pd.read_json(\"Data/Extended/ex_train.jsonl\", lines=True)\n",
    "\n",
    "        train_df = pd.concat([train_df, df_train_ex], ignore_index=True)\n",
    "\n",
    "    def balance_dataset(df, label_col='label'):\n",
    "        # Split by class\n",
    "        class_counts = df[label_col].value_counts()\n",
    "        minority_class = class_counts.idxmin()\n",
    "        majority_class = class_counts.idxmax()\n",
    "\n",
    "        # Sample from majority class to match minority count\n",
    "        df_minority = df[df[label_col] == minority_class]\n",
    "        df_majority = df[df[label_col] == majority_class].sample(n=len(df_minority), random_state=RANDOM_SEED)\n",
    "\n",
    "        # Concatenate and shuffle\n",
    "        balanced_df = pd.concat([df_minority, df_majority]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "        return balanced_df\n",
    "\n",
    "    train_df = balance_dataset(train_df)\n",
    "\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=RANDOM_SEED, stratify=train_df['label'])\n",
    "\n",
    "    test_df_seen = pd.read_json(\"Data/Original/test_seen.jsonl\", lines=True)\n",
    "    test_df_unseen = pd.read_json(\"Data/Original/test_unseen.jsonl\", lines=True)\n",
    "    test_df = pd.concat([test_df_seen, test_df_unseen], ignore_index=True)\n",
    "\n",
    "    if(not isExt):\n",
    "        print(\"(Original) Train/Val/Test Set Label Counts:\")\n",
    "    else:\n",
    "        print(\"(Extended) Train/Val/Test Set Label Counts:\")\n",
    "    print(\"Train:\")\n",
    "    print(train_df.label.value_counts())\n",
    "    print(\"Validation:\")\n",
    "    print(val_df.label.value_counts())\n",
    "    print(\"Test:\")\n",
    "    print(test_df.label.value_counts())\n",
    "\n",
    "    if(isExt):\n",
    "        print(\"\\n\\nLabel distribution (original vs aug) in Extended Dataset:\")\n",
    "        print(\"Train:\")\n",
    "        print(train_df[train_df['img'].str.contains(\"ex_\")].label.value_counts())\n",
    "        print(\"Validation:\")\n",
    "        print(val_df[val_df['img'].str.contains(\"ex_\")].label.value_counts())\n",
    "\n",
    "print_stats(False)\n",
    "print(\"\\n\" + \"#\" * 50 + \"\\n\")\n",
    "print_stats(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f800d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Label Counts:\n",
      "##################################################\n",
      "Seen:\n",
      "label\n",
      "0    510\n",
      "1    490\n",
      "Name: count, dtype: int64\n",
      "##################################################\n",
      "Unseen:\n",
      "label\n",
      "0    1250\n",
      "1     750\n",
      "Name: count, dtype: int64\n",
      "##################################################\n",
      "Combined Test:\n",
      "label\n",
      "0    1760\n",
      "1    1240\n",
      "Name: count, dtype: int64\n",
      "##################################################\n",
      "Total number of memes in Test Set:  3000\n"
     ]
    }
   ],
   "source": [
    "# Stats for testing dataset\n",
    "df_seen = pd.read_json(\"Data/Original/test_seen.jsonl\", lines=True)\n",
    "df_unseen = pd.read_json(\"Data/Original/test_unseen.jsonl\", lines=True)\n",
    "df_test = pd.concat([df_seen, df_unseen], ignore_index=True)\n",
    "\n",
    "print(\"Test Set Label Counts:\")\n",
    "print(\"#\" * 50)\n",
    "print(\"Seen:\")\n",
    "print(df_seen.label.value_counts())\n",
    "print(\"#\" * 50)\n",
    "print(\"Unseen:\")\n",
    "print(df_unseen.label.value_counts())\n",
    "print(\"#\" * 50)\n",
    "print(\"Combined Test:\")\n",
    "print(df_test.label.value_counts())\n",
    "print(\"#\" * 50)\n",
    "print(\"Total number of memes in Test Set: \", len(df_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MS_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
